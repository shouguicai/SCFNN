\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{bucker1976use,baggeroer1988matched,baggeroer1993overview}
\citation{tolstoy1989sensitivity,del1988effects}
\citation{thode2012automated}
\citation{steinberg1991neural}
\citation{ozard1991artificial}
\citation{niu2017source}
\citation{feuillade1989environmental}
\citation{niu2017source}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{goodfellow2016deep}
\citation{niu2017source}
\citation{bishop2006pattern}
\citation{goodfellow2016deep}
\@writefile{toc}{\contentsline {section}{\numberline {2}Sparse Neural Networks Based Source Localization}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Neural networks and function approximation}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Source localization prediction model}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Training the model with sparsity constraint and mixed data-model}{2}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Simulation and experimental results}{2}{section.3}}
\citation{porter1992kraken}
\citation{goodfellow2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Weights summary in hidden layer (left: no constraint, right: with constraint). Sparse constraint training makes the weight coefficients show group structure, either all zero, or basic is not zero.\relax }}{3}{figure.caption.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Parameter settings}{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Environment. An impressively detailed  environment model for SWellEx-96 experiment.\relax }}{3}{figure.caption.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The effect of sparsity constraint training}{3}{subsection.3.2}}
\citation{tolstoy1989sensitivity,feuillade1989environmental,del1988effects}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Model accuracy and average activation density for different $\lambda $. Regularization on neuron-level significantly reduces the average activation density and achieves good model accuracy. The model is trained on SWell96Ex-S5 experimental data.\relax }}{4}{figure.caption.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The learned sparse representation model. The learned feature space spans data(scm) space likelihood that few basis functions $\phi $ explains a given data.\relax }}{4}{figure.caption.8}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Localization accuracy of SCFNN and MFP on SWell96Ex-S5 experimental data\relax }}{4}{table.caption.9}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{my-label}{{1}{4}{Localization accuracy of SCFNN and MFP on SWell96Ex-S5 experimental data\relax \relax }{table.caption.9}{}}
\newlabel{my-label@cref}{{[table][1][]1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Comparison with conventional matched-field processing method}{4}{subsection.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Absolute mean error of SCFNN and MFP on SWell96Ex-S5 experimental data(m)\relax }}{4}{table.caption.10}}
\newlabel{my-label}{{2}{4}{Absolute mean error of SCFNN and MFP on SWell96Ex-S5 experimental data(m)\relax \relax }{table.caption.10}{}}
\newlabel{my-label@cref}{{[table][2][]2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Plots of sound speed profiles. The i906 has significant change in shape from the optimized, while the change in the i905 is slight. The i906{*} is slightly changed from i906, for the sake of testing.\relax }}{4}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}The influences of SSP mismatch on FNN classifier}{4}{subsection.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Increase model robustness by data-model mixed training}{4}{subsection.3.5}}
\bibstyle{unsrt}
\bibdata{acmart}
\bibcite{bucker1976use}{{1}{}{{}}{{}}}
\bibcite{baggeroer1988matched}{{2}{}{{}}{{}}}
\bibcite{baggeroer1993overview}{{3}{}{{}}{{}}}
\bibcite{tolstoy1989sensitivity}{{4}{}{{}}{{}}}
\bibcite{del1988effects}{{5}{}{{}}{{}}}
\bibcite{thode2012automated}{{6}{}{{}}{{}}}
\bibcite{steinberg1991neural}{{7}{}{{}}{{}}}
\bibcite{ozard1991artificial}{{8}{}{{}}{{}}}
\bibcite{niu2017source}{{9}{}{{}}{{}}}
\bibcite{feuillade1989environmental}{{10}{}{{}}{{}}}
\bibcite{goodfellow2016deep}{{11}{}{{}}{{}}}
\bibcite{bishop2006pattern}{{12}{}{{}}{{}}}
\bibcite{porter1992kraken}{{13}{}{{}}{{}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.62497pt}
\newlabel{tocindent2}{11.81937pt}
\newlabel{tocindent3}{22.09708pt}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces FNN positioning performance curve on simulation data (frequency:109,232,385Hz). FNN is also sensitive to SSP mismatch, but still performs better than Bartlett. \relax }}{5}{figure.caption.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces FNN positioning performance curve on simulation data. FNN model robustness can be by significantly improved by data-model mixed training\relax }}{5}{figure.caption.13}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Summary}{5}{section.4}}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.15}}
\newlabel{TotPages}{{5}{5}{}{page.5}{}}
